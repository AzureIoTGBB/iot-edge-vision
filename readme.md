# Vision on the Edge

## Introduction

Visual inspection of products, resources and environments has been a core practice for most Enterprises, and was, until recently, a very manual process. An individual, or group of individuals, was responsible for performing a manual inspection of the asset or environment, which, depending on the circumstances, could become inefficient, inaccurate or both, due to human error and limitations.

Our intent with this [guidance](/documentation/guidance.md) is to provide a detailed view at the technologies available today to allow enterprises to fully capitalize on the power of AI, Edge Computing and advancements in camera technologies to bring powerful vision at the edge solutions. 

## Guidance

The purpose of this document is to give some concrete guidance on some of the key decisions when designing an end-to-end vision on the edge solution. Specifically, we will address:

* [Camera selection and placement](documentation/guidance.md#camera-considerations)
* [Hardware acceleration](documentation/guidance.md#hardware-acceleration)
* [Machine learning and data science](documentation/guidance.md#machine-learning-and-data-science)
* [Image storage and management](documentation/guidance.md#image-storage-and-management)
* [Persistence of alerts](documentation/guidance.md#inferencing-results-persistence)
* [User Interface](documentation/guidance.md#user-interface)

## Sample Solution

As of the time of publication the architecture section is currently under development.  However, while we are finishing up the details on the architecture section we wanted to share out the guidance gathered within this documentation.  

